{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998b1f74-4a3e-473e-8a0a-fa35c1b099c7",
   "metadata": {},
   "source": [
    "# Workshop 1: Machine Learning for Mac\n",
    "## Step 1: Installing Homebrew and Python\n",
    "- Navigate to the Launch Pad\n",
    "- Search \"Terminal\"\n",
    "- Copy and paste the following commands into the terminal one at a time and hit enter after each command:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d4e9d",
   "metadata": {},
   "source": [
    "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03f90b",
   "metadata": {},
   "source": [
    "brew install python@3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a910221",
   "metadata": {},
   "source": [
    "## Step 2: Setup Python Virtual Environment\n",
    "- Within VS Code access the terminal at the bottom of the screen by going to the bottom of the main panel until your cursor changes into a up arrow then dragging up\n",
    "- Once, this panel is revealed, click on the \"terminal\" tab\n",
    "- If you already have a terminal type \"exit\" then hit enter then follow the instructions above\n",
    "- Now, copy and paste the following commands into the terminal one at a time (you can't use ctrl-v to paste into Powershells. You can just click on the cell and ctrl-c to copy it):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e389040",
   "metadata": {},
   "source": [
    "python3.11 -m venv ml-venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c3117",
   "metadata": {},
   "source": [
    "source ml-venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05fc41",
   "metadata": {},
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2ea76",
   "metadata": {},
   "source": [
    "## Step 3: Test PyTorch\n",
    "- Run the following code segment to verify that the virtual environment is working as intended\n",
    "    - When doing this, VS Code will prompt you for a kernel at the top of the screen\n",
    "    - Click on \"Python Environments\" then \"ml-venv\"\n",
    "- If VS Code prompts you to install something when you run the following code block, press \"Install\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da40286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f5cba",
   "metadata": {},
   "source": [
    "# Step 4: Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3994ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV data located in the data folder through pandas\n",
    "heartData = pd.read_csv('data/heart.csv')\n",
    "o2Data = pd.read_csv('data/o2Saturation.csv', header=None)\n",
    "\n",
    "# copy the O2 saturation data to the main pandas dataframe\n",
    "heartData['o2Saturation'] = o2Data\n",
    "\n",
    "# moe the output column to the end of the dataframe\n",
    "cols = list(heartData.columns)\n",
    "cols.remove('output')\n",
    "cols.append('output')\n",
    "heartData = heartData[cols]\n",
    "\n",
    "# normalize the dataset between 0 and 1\n",
    "for col in heartData.columns:\n",
    "    # these columns are already between 0 and 1 so we don't need to normalize them\n",
    "    if col == 'output' or col == 'sex' or col == 'fbs' or col == 'exng': continue\n",
    "\n",
    "    # normalize the data by subtracting the minimum value and dividing by the range\n",
    "    heartData[col] = (heartData[col] - heartData[col].min()) / (heartData[col].max() - heartData[col].min())\n",
    "\n",
    "# display the first 5 rows of the dataframe to give an idea of what the data looks like\n",
    "heartData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf678f",
   "metadata": {},
   "source": [
    "# Step 5: Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15648efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training set with be 80% of the data, this randomly selects 80% of the data and resets the index\n",
    "train = heartData.sample(frac=0.8, random_state=42)\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "# the validation and test set will each be 10% of the data\n",
    "# after the training set is removed from the data, the remaining data is split in half, one half for validation and the other for testing\n",
    "validation = heartData.drop(train.index)\n",
    "test = validation.sample(frac=0.5, random_state=42)\n",
    "validation = validation.drop(test.index)\n",
    "\n",
    "# reset the index of the validation and test sets\n",
    "validation = validation.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7717e",
   "metadata": {},
   "source": [
    "## Step 5.5: Visualizing Connections\n",
    "- The following code displays the correlation coefficient between each of the 14 variables and the output variable\n",
    "- As you may notice, none of the variables on their own can accurately predict whether the patient will experience a heart attack\n",
    "- This is why a holistic analysis of the data using deep learning is advantagous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e83729",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 1))\n",
    "sns.heatmap(train.corr()[['output']].T, annot=True, cmap='coolwarm', fmt='.2f', cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099dd198",
   "metadata": {},
   "source": [
    "# Step 6: Define a Dataset Object\n",
    "- To make the data easier to parse through while training, PyTorch offers a Dataset class we can inherant and implement for our own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will inherit the torch Dataset class and override the __len__ and __getitem__ methods\n",
    "class HeartDataset(torch.utils.data.Dataset):\n",
    "    # the constructor will take a dataframe as an argument\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    # the __len__ method will return the number of rows in the dataframe\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # everytime we parse through the dataset, this method will be called\n",
    "    def __getitem__(self, idx):\n",
    "        # get the row at the current\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # the input will be all the columns except the output column because the output column is the answer\n",
    "        input = torch.tensor(row.drop('output').values, dtype=torch.float32)\n",
    "        \n",
    "        # the expected output will be the output column\n",
    "        output = torch.tensor(row['output'], dtype=torch.float32)\n",
    "\n",
    "        # new need to reshape the tensor from a row vector to a column vector so the answer can be lined up with the output of the model\n",
    "        output = output.reshape(1)\n",
    "\n",
    "        # return the input and expected output\n",
    "        return input, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062392b",
   "metadata": {},
   "source": [
    "# Step 7: Design the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ca8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartAttackModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86e99f",
   "metadata": {},
   "source": [
    "# Step 8: Create Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d723c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, learningRate): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366d1fcf",
   "metadata": {},
   "source": [
    "# Step 9: Initialize Objects and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0900f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a01f792",
   "metadata": {},
   "source": [
    "# Step 10: Test Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf70c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ead058",
   "metadata": {},
   "source": [
    "Link to dataset: https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
